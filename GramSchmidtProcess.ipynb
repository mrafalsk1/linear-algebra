{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "verySmallNumber = 1e-14 # That's 1×10⁻¹⁴ = 0.00000000000001\n",
    "\n",
    "# Our first function will perform the Gram-Schmidt procedure for 4 basis vectors.\n",
    "# We'll take this list of vectors as the columns of a matrix, A.\n",
    "# We'll then go through the vectors one at a time and set them to be orthogonal\n",
    "# to all the vectors that came before it. Before normalising.\n",
    "def gsBasis4(A) :\n",
    "    B = np.array(A, dtype=np.float_) # Make B as a copy of A, since we're going to alter it's values.\n",
    "    # The zeroth column is easy, since it has no other vectors to make it normal to.\n",
    "    # All that needs to be done is to normalise it. I.e. divide by its modulus, or norm.\n",
    "    B[:, 0] = B[:, 0] / la.norm(B[:, 0])\n",
    "    # For the first column, we need to subtract any overlap with our new zeroth vector.\n",
    "    B[:, 1] = B[:, 1] - B[:, 1] @ B[:, 0] * B[:, 0]\n",
    "    # If there's anything left after that subtraction, then B[:, 1] is linearly independant of B[:, 0]\n",
    "    # If this is the case, we can normalise it. Otherwise we'll set that vector to zero.\n",
    "    if la.norm(B[:, 1]) > verySmallNumber :\n",
    "        B[:, 1] = B[:, 1] / la.norm(B[:, 1])\n",
    "    else :\n",
    "        B[:, 1] = np.zeros_like(B[:, 1])\n",
    "    # Now we need to repeat the process for column 2.\n",
    "    B[:, 2] = B[:, 2] - B[:, 2] @ B[:, 0] * B[:, 0]\n",
    "    B[:, 2] = B[:, 2] - B[:, 2] @ B[:, 1] * B[:, 1]\n",
    "    \n",
    "    \n",
    "     \n",
    "    # Again we'll need to normalise our new vector.\n",
    "    if la.norm(B[:,2]) > verySmallNumber:\n",
    "        B[:,2] = B[:,2] / la.norm(B[:,2])\n",
    "    else:\n",
    "        B[:,2] = np.zeros_like[B[:,2]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Finally, column three:\n",
    "    B[:, 3] = B[:, 3] - B[:, 3] @ B[:, 0] * B[:, 0]\n",
    "    B[:, 3] = B[:, 3] - B[:, 3] @ B[:, 1] * B[:, 1]\n",
    "    B[:, 3] = B[:, 3] - B[:, 3] @ B[:, 2] * B[:, 2]\n",
    "    \n",
    "    \n",
    "    # Now normalise if possible\n",
    "    if la.norm(B[:,3]) > verySmallNumber:\n",
    "        B[:,3] = B[:,3] / la.norm(B[:,3])\n",
    "    else:\n",
    "        B[:,3] = np.zeros_like[B[:,3]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Finally, we return the result:\n",
    "    return B\n",
    "\n",
    "# Previously, we could only have four vectors, and there was a lot of repeating in the code.\n",
    "# We'll use a for-loop here to iterate the process for each vector.\n",
    "def gsBasis(A) :\n",
    "    B = np.array(A, dtype=np.float_) # Make B as a copy of A, since we're going to alter it's values.\n",
    "    # Loop over all vectors, starting with zero, label them with i\n",
    "    for i in range(B.shape[1]) :\n",
    "        # Inside that loop, loop over all previous vectors, j, to subtract.\n",
    "        for j in range(i) :\n",
    "            # you'll need the current vector B[:, i] and a previous vector B[:, j]\n",
    "            B[:, i] = B[:, i] - B[:, i] @ B[:, j] * B[:, j]\n",
    "        if la.norm(B[:, i]) > verySmallNumber:\n",
    "            B[:, i] = B[:, i] / la.norm(B[:, i])\n",
    "        else:\n",
    "            B[:, i] = np.zeros_like(B[:, i])\n",
    "            \n",
    "            \n",
    "          \n",
    "            \n",
    "    # Finally, we return the result:\n",
    "    return B\n",
    "\n",
    "# This function uses the Gram-schmidt process to calculate the dimension\n",
    "# spanned by a list of vectors.\n",
    "# Since each vector is normalised to one, or is zero,\n",
    "# the sum of all the norms will be the dimension.\n",
    "def dimensions(A) :\n",
    "    return np.sum(la.norm(gsBasis(A), axis=0))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
